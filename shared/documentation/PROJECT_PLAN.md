# Experimental Theatre Digital Program - Project Plan

## 1. Project Goal

To create a digital program for an experimental theatre piece that involves:
1.  Automatically collecting images of audience faces from an SD card inserted into `computer1`.
2.  Processing these images on `computer1` to detect and crop out eyes.
3.  Applying real-time artistic texture processing with live preview gallery displaying processed textures in original aspect ratios.
4.  Serving a web-based visual client from `computer1` to `computer2` (which can only run a web browser).
5.  The client on `computer2` will display the processed eye images in real-time with a texture preview gallery.
6.  Upon a keyboard shortcut trigger from `computer1`, the client on `computer2` will transition to a dynamic 4-phase 3D animation using `Three.js`, featuring enhanced flow dynamics, professional bloom effects, convergence animation, dispersion burst, and shell formation with organic morphing eye-textured shapes creating a flowing, living digital creature.
7.  **ğŸ¬ Progressive Camera Animation System** - Camera rotation speed progressively increases from 10% to 100% based on audience participation (number of eye shapes), creating direct connection between audience engagement and visual energy.
8.  **ğŸ”„ NEW: Organic Shape Morphing System** - Eye-textured shapes constantly morph using vertex noise, creating living, breathing appearance that makes the digital creature appear truly alive.

## 2. Overall Architecture

The system will operate with two computers in the same local network:

*   **`computer1` (Windows):** Acts as the central processing unit and server.
    *   Handles all image acquisition from the SD card with automatic detection and import.
    *   Performs image processing (eye detection and cropping).
    *   Hosts the web server (Flask) that serves the client application.
    *   Manages real-time communication (Flask-SocketIO) with the client.
    *   Listens for a global keyboard shortcut to trigger the main animation.
*   **`computer2` (Any OS with a modern Web Browser):** Acts as a display client.
    *   Loads and runs a web application served by `computer1`.
    *   Cannot run any native code; all logic is client-side JavaScript.
    *   Receives data and signals from `computer1` to update visuals.
    *   Displays 4-phase interactive 3D visual effects with enhanced flow dynamics, professional bloom post-processing, and progressive camera rotation system.

## 3. Technology Stack

*   **Backend (`computer1` - Python):**
    *   **SD Card Detection & File Operations:** `psutil` (for drive detection), `os`, `shutil`.
    *   **Image Processing:** `OpenCV-Python` (for face/eye detection), `Pillow` (for image manipulation).
    *   **Folder Monitoring:** `watchdog`.
    *   **Web Framework:** `Flask`.
    *   **Real-time Communication:** `Flask-SocketIO`.
    *   **Keyboard Listener:** `keyboard` library.
    *   **Dependency Management:** `pip` with `requirements.txt`.
*   **Frontend (`computer2` - Browser, code served from `computer1`):**
    *   **Structure:** HTML5.
    *   **Styling:** CSS3.
    *   **Logic & Interactivity:** JavaScript (ES6+).
    *   **3D Graphics:** `Three.js`.
    *   **Real-time Communication Client:** `Socket.IO Client JS library`.
    *   **Image Display/Filtering (Optional):** HTML Canvas API.

## 4. Component Breakdown

### 4.1. Computer 1: Backend & Server (Python)

#### 4.1.1. SD Card Monitor & Image Importer
*   **Objective:** Detect SD card insertion and copy new images.
*   **Tasks:**
    *   Periodically scan for newly connected drives/volumes using `psutil`.
    *   Identify the SD card (e.g., by volume name or presence of a specific marker file/folder).
    *   Once detected, iterate through image files (e.g., `.jpg`, `.png`) on the SD card.
    *   Copy only new images (not previously imported) to a designated `data/originals/` folder on `computer1`. Maintain a list or mechanism to track imported files.
*   **File:** `computer1_backend/sd_card_monitor.py` (can be a standalone script or a module integrated into `main_server.py`).

#### 4.1.2. Eye Detection & Cropping Service
*   **Objective:** Process images from `data/originals/` to extract eyes.
*   **Tasks:**
    *   Use `watchdog` to monitor the `data/originals/` folder for new image files.
    *   For each new image:
        *   Load the image using `OpenCV`.
        *   Perform face detection (e.g., using Haar cascades or a more modern DNN model).
        *   For each detected face, perform eye detection.
        *   Crop the regions corresponding to the detected eyes.
        *   Save the cropped eye images to the `data/cropped_eyes/` folder (e.g., `eye_timestamp_1.jpg`, `eye_timestamp_2.jpg`).
        *   After processing, notify the web server (e.g., via an internal queue or a Socket.IO emit from the server itself) that new eye images are available.
*   **File:** `computer1_backend/image_processor.py` (can be a standalone script or a module).

#### 4.1.3. Web Application Server (Flask)
*   **Objective:** Serve the client application and image data.
*   **Tasks:**
    *   Initialize Flask and Flask-SocketIO.
    *   Define a route to serve the main `index.html` for the client.
    *   Define routes to serve static assets (CSS, client-side JS, `Three.js` library, `Socket.IO` client library, and images in `static/other_images_for_animation/`).
    *   Define a route or mechanism to serve images from the `data/cropped_eyes/` folder (e.g., `/eyes/<filename>`).
*   **File:** `computer1_backend/main_server.py`.

#### 4.1.4. Real-time Communication (Flask-SocketIO)
*   **Objective:** Facilitate communication between server and client.
*   **Tasks (within `main_server.py`):**
    *   Handle client connections and disconnections.
    *   When the `image_processor.py` signals that new eye images are ready:
        *   Emit a `new_eye_image_available` event to all connected clients, sending the path/URL of the new eye image(s).
    *   When the `keyboard_listener.py` detects the trigger shortcut:
        *   Emit a `trigger_final_animation` event to all connected clients.
*   **File:** `computer1_backend/main_server.py`.

#### 4.1.5. Keyboard Shortcut Listener
*   **Objective:** Detect a global keyboard shortcut on `computer1` to trigger the animation.
*   **Tasks:**
    *   Use the `keyboard` library to listen for a specific key combination (e.g., Down Arrow).
    *   When the combination is detected, send a signal to the `main_server.py` (e.g., via an internal HTTP request to a specific Flask endpoint, or by directly calling a function if running in the same process/thread, or via a shared event queue). The server will then relay this as a Socket.IO event.
*   **File:** `computer1_backend/keyboard_listener.py` (standalone script).

### 4.2. Computer 2: Web Client (Browser, served from `computer1`)

#### 4.2.1. HTML Structure & Asset Loading
*   **Objective:** Basic webpage structure.
*   **Tasks:**
    *   Create `index.html` with placeholders for dynamic content.
    *   Include `<script>` tags for `Socket.IO` client, `Three.js`, and custom `client.js`.
    *   Include `<link>` tag for `style.css`.
    *   Container elements for eye image display and the Three.js canvas.
*   **File:** `computer1_backend/templates/index.html`.

#### 4.2.2. Real-time Communication Client (Socket.IO JS)
*   **Objective:** Connect to the server and handle events.
*   **Tasks (within `client.js`):**
    *   Establish a Socket.IO connection to `computer1`'s server.
    *   Listen for `new_eye_image_available` events:
        *   On event, receive image URL/path.
        *   Call functions to display the new eye image.
    *   Listen for `trigger_final_animation` events:
        *   On event, call functions to initiate the Three.js animation sequence.
*   **File:** `computer1_backend/static/js/client.js`.

#### 4.2.3. Eye Image Display
*   **Objective:** Show incoming eye images.
*   **Tasks (within `client.js`):**
    *   Function to dynamically add new eye images to the display area (e.g., append `<img>` tags or draw to a 2D canvas).
    *   Implement logic for how images are displayed (e.g., one by one, fading in/out, grid).
    *   Optional: Apply client-side filters using the Canvas API if desired.
*   **File:** `computer1_backend/static/js/client.js`.

#### 4.2.4. Three.js Animation Engine
*   **Objective:** Create and manage the 3D animation.
*   **Tasks (within `client.js` or a dedicated `animation.js` module):**
    *   **Scene Setup:**
        *   Initialize Three.js scene, camera, renderer.
        *   Load the "other images" (from `computer1_backend/static/other_images_for_animation/`) as textures for 3D meshes.
        *   Position these meshes initially (e.g., scattered, semi-transparent).
    *   **Animation Logic:**
        *   Function to be called on `trigger_final_animation` event.
        *   Animate meshes blending/morphing into a sphere-like structure.
        *   Animate this structure flowing or moving across the screen.
        *   Handle the render loop.
*   **File:** `computer1_backend/static/js/client.js` (or potentially a separate JS file imported by it).

## 5. Data Management

*   **Source Images (SD Card):** Temporarily accessed.
*   **Originals:** Stored in `Program/computer1_backend/data/originals/`. Copied from SD card.
*   **Cropped Eyes:** Stored in `Program/computer1_backend/data/cropped_eyes/`. Generated by `image_processor.py`. Served to the client.
*   **Animation Assets:** Stored in `Program/computer1_backend/static/other_images_for_animation/`. Pre-loaded images for the Three.js animation. Served to the client.

## 6. Proposed Directory Structure

```
Program/
â”œâ”€â”€ computer1_backend/
â”‚   â”œâ”€â”€ sd_card_monitor.py
â”‚   â”œâ”€â”€ image_processor.py
â”‚   â”œâ”€â”€ main_server.py
â”‚   â”œâ”€â”€ keyboard_listener.py
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”‚   â”œâ”€â”€ client.js
â”‚   â”‚   â”‚   â”œâ”€â”€ three.min.js        # (or other version)
â”‚   â”‚   â”‚   â””â”€â”€ socket.io.min.js    # (or other version)
â”‚   â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”‚   â””â”€â”€ style.css
â”‚   â”‚   â””â”€â”€ other_images_for_animation/
â”‚   â”‚       â””â”€â”€ (e.g., image1.jpg, image2.png)
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ originals/
â”‚   â”‚   â””â”€â”€ cropped_eyes/
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ shared/
    â””â”€â”€ documentation/
        â””â”€â”€ PROJECT_PLAN.md
    â””â”€â”€ test_images/
        â””â”€â”€ (Example images for testing)
```
*(The `computer2/` directory is omitted as all client files are served from `computer1_backend`)*

## 7. Development Steps / Milestones

### âœ… **M1: Basic Server & Client Setup** - COMPLETED
*   âœ… Create `computer1_backend` directory structure.
*   âœ… Setup `requirements.txt` with all dependencies (`Flask`, `Flask-SocketIO`, `OpenCV`, `Pillow`, etc.).
*   âœ… Implement Flask server (`main_server.py`) serving `index.html` with Socket.IO support.
*   âœ… Create beautiful, theatrical HTML template (`templates/index.html`) with eye display and Three.js canvas areas.
*   âœ… Implement comprehensive CSS styling (`static/css/style.css`) with dark theme and smooth animations.
*   âœ… Download and integrate Three.js and Socket.IO client libraries.
*   âœ… Create client-side JavaScript (`static/js/client.js`) with Socket.IO connection and basic Three.js scene.
*   âœ… Implement debug panel with connection status and test buttons.
*   âœ… Create `run.py` script for easy server startup.
*   âœ… Create comprehensive README with setup and usage instructions.
*   âœ… Test dependencies installation and basic server functionality.

### âœ… **M2: Image Processing Core** - COMPLETED
*   âœ… Create test images in `shared/test_images/` directory for development
*   âœ… Develop `image_processor.py` with OpenCV face and eye detection
*   âœ… Implement comprehensive error handling and fallback eye generation
*   âœ… Add automatic file monitoring using `watchdog` library
*   âœ… Integrate real-time Socket.IO notifications for new processed eyes
*   âœ… Test face detection with various image types and qualities
*   âœ… Create eye images gallery display system in web client
*   âœ… Add auto-loading of existing eye images on client connection

### âœ… **M3: SD Card Auto-Import System** - COMPLETED
*   âœ… Implement intelligent SD card detection using `psutil`
*   âœ… Create comprehensive SD card management interface
*   âœ… Add background import system with real-time progress tracking
*   âœ… Implement duplicate prevention using SHA-256 hashing
*   âœ… Create professional UI with configuration controls and status indicators
*   âœ… Add auto-import toggle with robot emoji indicators
*   âœ… Integrate seamless pipeline: SD Card â†’ Import â†’ Eye Processing â†’ Display

### âœ… **M4: Visual Effects System** - COMPLETED
*   âœ… Complete 3-phase interactive 3D visual effects system
*   âœ… Enhanced particle system with depth-based effects and configurable parameters
*   âœ… Eye-textured 3D shapes with automatic texture loading
*   âœ… Dramatic convergence animation with speed acceleration
*   âœ… Automatic phase transitions based on eye image detection
*   âœ… Mouse grab orbital camera controls for interactive viewing

### âœ… **M5: Advanced Configurable Visual Effects** - COMPLETED
*   âœ… Complete configuration system with 40+ visual parameters
*   âœ… Enhanced flow dynamics system preventing particle belt formation
*   âœ… Real-time flow control toggle for comparing simple vs enhanced systems
*   âœ… Enhanced Phase 1 with center attraction and infinite particle persistence
*   âœ… Advanced particle system with distance-based opacity and HSL colors
*   âœ… Flexible rendering with configurable geometry and material properties
*   âœ… Enhanced scene control and performance optimization settings

### âœ… **M6: Constant Bloom Emission System** - COMPLETED
*   âœ… Professional Three.js UnrealBloomPass integration
*   âœ… Constant light emission with particles acting as individual light bulbs
*   âœ… Optimized bloom settings for strong constant emission
*   âœ… Real-time bloom controls in debug panel
*   âœ… Enhanced material system with emissive properties
*   âœ… Adaptive quality settings with performance monitoring

### âœ… **M7: Global Keyboard Trigger System** - COMPLETED
*   âœ… Global hotkey support using Python `keyboard` library
*   âœ… Down arrow key trigger with 2-second cooldown safety
*   âœ… Real-time Socket.IO integration for instant client notification
*   âœ… Live keyboard listener status monitoring in web interface
*   âœ… Background operation with comprehensive error handling

### âœ… **M8: Enhanced Flow Dynamics System** - COMPLETED
*   âœ… Revolutionary 6-mechanism particle physics system
*   âœ… Balanced vs simple attraction modes with force distribution
*   âœ… Circulation forces for tangential particle motion around shapes
*   âœ… Global flow field with animated background currents
*   âœ… Enhanced turbulence and escape velocity systems
*   âœ… Repulsion zones preventing particle trapping
*   âœ… Real-time toggle control for system comparison

### âœ… **M9: Client-Side Artistic Texture Processing** - COMPLETED
*   âœ… Complete artistic processing pipeline with real-time edge detection
*   âœ… Three sophisticated algorithms (Sobel, Roberts, Prewitt)
*   âœ… High-performance off-screen canvas processing with smart caching
*   âœ… Comprehensive UI controls with 12+ adjustable parameters
*   âœ… Artistic enhancement pipeline with multiple processing stages
*   âœ… 3D integration with emissive glow effects and bloom compatibility
*   âœ… Advanced configuration system with professional control panel
*   âœ… Real-time texture display gallery with live preview capabilities
*   âœ… Original aspect ratio display with interactive controls
*   âœ… Auto-refresh system and texture management features

### âœ… **M10: Dynamic Camera Rotation System** - COMPLETED ğŸ“·
*   âœ… **ğŸ¬ Progressive Camera Animation**: Revolutionary camera system that builds energy as audience participates
*   âœ… **ğŸ“ˆ Speed-Based Progression**: Camera rotation speed increases from 10% to 100% based on number of eye shapes (0 to 40 shapes)
*   âœ… **ğŸŒ 3D Orbital Motion**: Both horizontal continuous rotation and vertical oscillating motion for dynamic cinematic experience
*   âœ… **âš¡ Real-Time Speed Calculation**: `speed = 0.1 + (currentShapes/maxShapes) * 0.9` provides smooth acceleration curve
*   âœ… **ğŸ›ï¸ Comprehensive UI Monitoring**: Live camera rotation status with color-coded indicators:
     - **ğŸŸ¢ Slow (10-30%)**: Green progress bar and "Slow Rotation" status
     - **ğŸŸ¡ Medium (30-70%)**: Yellow progress bar and "Medium Rotation" status  
     - **ğŸ”´ Fast (70-100%)**: Red progress bar and "Fast Rotation" status
*   âœ… **ğŸ“Š Live Performance Metrics**: Real-time display of current speed percentage, shape count (current/max), and rotation status
*   âœ… **âœ¨ Animated Progress Bar**: Shimmer effect and smooth transitions with hover interactions
*   âœ… **ğŸª Theatre Integration**: Creates direct connection between audience participation and visual energy
*   âœ… **âš™ï¸ Configurable Parameters**: Base speeds, oscillation range, and visual feedback all easily adjustable
*   âœ… **ğŸ® User Interaction Friendly**: Camera system works seamlessly with mouse grab orbital controls

### âœ… **M11: Organic Shape Morphing System** - COMPLETED ğŸ”„
*   âœ… **ğŸŒ± Living Eye Shapes**: Revolutionary vertex noise morphing system creating organic, constantly changing 3D shapes that appear alive and breathing
*   âœ… **ğŸ”„ Vertex Noise Implementation**: Real-time vertex displacement using multi-octave mathematical functions (sine/cosine waves) for natural, flowing movement
*   âœ… **ğŸ­ Simplified Architecture**: Focused on vertex noise rather than complex geometric morphing for better performance and more organic results
*   âœ… **ğŸ›ï¸ Advanced Morphing Controls**: Complete UI control panel with 5 real-time adjustable parameters:
     - **Noise Animation Speed** (0.1-2.0): Controls how fast the vertex noise animates over time
     - **Noise Intensity** (0.0-1.0): Overall strength of vertex displacement effects
     - **Noise Frequency** (0.5-5.0): Detail level of noise pattern (higher = more intricate deformation)
     - **Noise Amplitude** (0.01-0.5): Maximum displacement distance for individual vertices
     - **Global Enable/Disable**: Master switch for the entire morphing system
*   âœ… **ğŸ¨ Base Shape Variety**: Each morphing shape randomly chooses between cube or bipyramid as foundation, maintaining original shape recognition while adding organic movement
*   âœ… **âš¡ High-Performance Implementation**: Optimized vertex manipulation with original vertex preservation and efficient normal recalculation
*   âœ… **ğŸ” Advanced Debugging System**: Comprehensive debugging tools including:
     - **Vertex Storage Verification**: Logs when vertices are stored and validates geometry data
     - **Displacement Tracking**: Real-time monitoring of maximum displacement values being applied
     - **Extreme Test Mode**: Debug button for dramatic wobbling to verify system functionality
     - **Performance Logging**: Tracks morphing activity, timer progression, and effect intensity
*   âœ… **ğŸŒŠ Phase Integration**: Seamless integration with existing visual phases and convergence animations
*   âœ… **ğŸ’« Organic Appearance**: Creates breathing, pulsing, living shapes that enhance the theatrical experience with subtle but noticeable movement
*   âœ… **ğŸª Theatre-Ready**: Production-optimized settings providing dramatic organic movement without overwhelming the core eye-texture visibility
*   âœ… **âš™ï¸ Memory Efficient**: Smart original vertex storage and disposal system prevents memory leaks during long performances
*   âœ… **ğŸ”„ Reset Capability**: Complete reset to original geometry during convergence reset and shape disposal

### ğŸ‰ **CORE THEATRE PRODUCTION SYSTEM COMPLETE**
All essential components for professional live theatre production are now fully implemented and operational:
- âœ… **ğŸ¤– SD Card Auto-Import**: Automatic detection and background processing
- âœ… **ğŸ‘ï¸ Eye Detection & Processing**: Real-time image processing pipeline  
- âœ… **ğŸ¨ Client-Side Artistic Processing**: Real-time B&W edge detection with professional control panel
- âœ… **âœ¨ 3D Visual Effects**: Professional configurable animation system with constant bloom emission
- âœ… **ğŸŒŠ Enhanced Flow Dynamics**: Revolutionary 6-mechanism particle physics system
- âœ… **ğŸ“· Dynamic Camera Rotation**: Progressive speed-up system connected to audience participation
- âœ… **ğŸ¹ Keyboard Triggers**: Global hotkey system for live performance control
- âœ… **ğŸ”„ Real-time Communication**: Complete Socket.IO integration with comprehensive status monitoring

### ğŸª **Live Theatre Operation Workflow**
1. **ğŸ¬ Setup**: Start server, open web client on display computer
2. **ğŸ“¸ Image Collection**: Insert camera SD card â†’ Automatic detection and import
3. **ğŸ‘ï¸ Processing**: Real-time eye detection and artistic texture processing
4. **ğŸ”„ Organic Animation**: Eye shapes begin morphing with vertex noise, creating living, breathing appearance
5. **ğŸ¨ Visual Development**: Progressive camera rotation accelerates as more audience eyes appear with organic movement
6. **ğŸ¹ Performance Control**: Down arrow key triggers dramatic convergence animation with morphing shapes
7. **âœ¨ Visual Spectacle**: Professional bloom effects, flow dynamics, organic morphing, and dynamic camera create engaging theatre experience
8. **ğŸ”„ Reset**: Easy animation reset for multiple performances (morphing shapes return to original geometry)

The system is now **production-ready** for live theatre implementation with all core functionality operational and tested.

This plan provides a comprehensive roadmap. We can adjust and elaborate on specific sections as development progresses. 

- âœ¨ Complete 4-phase visual effects system with enhanced flow dynamics, constant bloom emission, and client-side artistic texture processing âœ… 